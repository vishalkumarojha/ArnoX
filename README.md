# ArnoX

ArnoX is an innovative image-to-speech narration app designed to assist visually impaired individuals. The app captures photos of objects, describes their appearance, recognizes written characters, and narrates them effectively. Developed as part of the Project Exhibition 1 at VIT Bhopal University, ArnoX aims to make daily life easier for visually impaired users.

## Tech Stacks Used
1. **Mobile Development:** Built using Flutter, Dart, and Android Studio for seamless cross-platform compatibility.
2. **ML Integration:** Leveraged Google ML Kit for object detection and text recognition.
3. **OCR Support:** Incorporated Tesseract OCR for robust text extraction.
4. **Cloud Services:** Firebase for data handling, authentication, and real-time updates.
5. **Text-to-Speech:** Implemented Flutter TTS for natural and clear audio narration.
6. **Dependencies:** Included powerful libraries like `flutter_screenutil`, `image_picker`, and `GetX` for state management.

## What Makes ArnoX Unique
1. **Dual Functionality:** Combines object detection and text recognition in a single app, offering a comprehensive solution for visually impaired users.
2. **Real-Time Narration:** Provides immediate audio feedback, enhancing usability in everyday scenarios.
3. **Cross-Platform Efficiency:** Built using Flutter, ensuring a consistent and responsive user experience.
4. **Scalable Architecture:** Utilizes Firebase for seamless data management, making the app highly scalable for future enhancements.

## Future Directions
We aim to expand ArnoX's capabilities by incorporating video description features, providing even greater accessibility and utility for our users.

## Acknowledgments
Special thanks to **Dr. Swagat Kumar Samantaray**, our supervisor, and to my amazing teammates:
- **Abhishek Kumar**
- **Rishav Mishra**
- **Mansi Kaushik**
- **Saniya Saw**

## Demo Video
Watch the demo video below to see ArnoX in action:
[Demo Video Link](https://lnkd.in/djsQA8Vf)


